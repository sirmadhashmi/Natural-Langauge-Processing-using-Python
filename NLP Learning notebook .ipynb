{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "## libraries requried to perform NLP(natural language processing using NLTK)\n",
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import blankline_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk import ne_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to C:\\Users\\Sirmad\n",
      "[nltk_data]     Hashmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Sirmad\n",
      "[nltk_data]     Hashmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sirmad\n",
      "[nltk_data]     Hashmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sirmad\n",
      "[nltk_data]     Hashmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sirmad Hashmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Sirmad\n",
      "[nltk_data]     Hashmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Sirmad\n",
      "[nltk_data]     Hashmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## file downloads for thoses who dont have NLTK library install via download from NLTK websites\n",
    "## gutenberg is english novels dataset\n",
    "nltk.download('gutenberg')\n",
    "## punkt requires for tokenize import \n",
    "nltk.download('punkt')\n",
    "## wordnet requires for lemmatization\n",
    "nltk.download('wordnet')\n",
    "## stop words download \n",
    "nltk.download('stopwords')\n",
    "## averaged_perceptron requires for post tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "## maxent_ne_chunker requires for NER also requires words\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## view in to all the files in gutenberg dataset\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating first variable for \"hamlet by shakespeare\"\n",
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
     ]
    },
    {
     "data": {
      "text/plain": [
       "37360"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## looking in to first 500 words in \n",
    "for word in hamlet[:500]:\n",
    "    print(word, sep =\" \" , end = \" \")\n",
    "len(hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Sirmad Mahmood Hashmi. I am an MSc Computer Science student at the University of Debrecen, Hungary. I am very much interested in deep learning, computer vision, and natural language processing. I am looking for a job as a data science engineer in the field of NLP or Computer Vision. As a hobbyist, I am a graphic designer I sometimes work as a freelance graphic designer. My favorite tool for graphic design is Coreldraw. I have also worked on several video projects editing projects and 3d animations. I have also built a video game for the Android platform using the unity3d engine. As a computer science student, I have decent knowledge in the field of cybersecurity and software development but now i am only working on machine learning concepts. My favorite programming languages are Python, R, C++, and, Java.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating your first string for processing \n",
    "test_str = \"Hello, I am Sirmad Mahmood Hashmi. I am an MSc Computer Science student at the University of Debrecen, Hungary. I am very much interested in deep learning, computer vision, and natural language processing. I am looking for a job as a data science engineer in the field of NLP or Computer Vision. As a hobbyist, I am a graphic designer I sometimes work as a freelance graphic designer. My favorite tool for graphic design is Coreldraw. I have also worked on several video projects editing projects and 3d animations. I have also built a video game for the Android platform using the unity3d engine. As a computer science student, I have decent knowledge in the field of cybersecurity and software development but now i am only working on machine learning concepts. My favorite programming languages are Python, R, C++, and, Java.\"\n",
    "print(test_str)\n",
    "type(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Sirmad',\n",
       " 'Mahmood',\n",
       " 'Hashmi',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'an',\n",
       " 'MSc',\n",
       " 'Computer',\n",
       " 'Science',\n",
       " 'student',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Debrecen',\n",
       " ',',\n",
       " 'Hungary',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'very',\n",
       " 'much',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'computer',\n",
       " 'vision',\n",
       " ',',\n",
       " 'and',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'a',\n",
       " 'job',\n",
       " 'as',\n",
       " 'a',\n",
       " 'data',\n",
       " 'science',\n",
       " 'engineer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'or',\n",
       " 'Computer',\n",
       " 'Vision',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'hobbyist',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'graphic',\n",
       " 'designer',\n",
       " 'I',\n",
       " 'sometimes',\n",
       " 'work',\n",
       " 'as',\n",
       " 'a',\n",
       " 'freelance',\n",
       " 'graphic',\n",
       " 'designer',\n",
       " '.',\n",
       " 'My',\n",
       " 'favorite',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'graphic',\n",
       " 'design',\n",
       " 'is',\n",
       " 'Coreldraw',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'also',\n",
       " 'worked',\n",
       " 'on',\n",
       " 'several',\n",
       " 'video',\n",
       " 'projects',\n",
       " 'editing',\n",
       " 'projects',\n",
       " 'and',\n",
       " '3d',\n",
       " 'animations',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'also',\n",
       " 'built',\n",
       " 'a',\n",
       " 'video',\n",
       " 'game',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Android',\n",
       " 'platform',\n",
       " 'using',\n",
       " 'the',\n",
       " 'unity3d',\n",
       " 'engine',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'student',\n",
       " ',',\n",
       " 'I',\n",
       " 'have',\n",
       " 'decent',\n",
       " 'knowledge',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'cybersecurity',\n",
       " 'and',\n",
       " 'software',\n",
       " 'development',\n",
       " 'but',\n",
       " 'now',\n",
       " 'i',\n",
       " 'am',\n",
       " 'only',\n",
       " 'working',\n",
       " 'on',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'concepts',\n",
       " '.',\n",
       " 'My',\n",
       " 'favorite',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'are',\n",
       " 'Python',\n",
       " ',',\n",
       " 'R',\n",
       " ',',\n",
       " 'C++',\n",
       " ',',\n",
       " 'and',\n",
       " ',',\n",
       " 'Java',\n",
       " '.']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating first tokken\n",
    "first_token = word_tokenize(test_str)\n",
    "first_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## length of tokken\n",
    "len(first_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checkin frequency\n",
    "fdist = FreqDist()\n",
    "for word in first_token:\n",
    "    fdist[word.lower()]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 10, 'i': 10, '.': 10, 'a': 7, 'am': 6, 'the': 5, 'computer': 4, 'and': 4, 'as': 4, 'science': 3, ...})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(',', 10),\n",
       " ('i', 10),\n",
       " ('.', 10),\n",
       " ('a', 7),\n",
       " ('am', 6),\n",
       " ('the', 5),\n",
       " ('computer', 4),\n",
       " ('and', 4),\n",
       " ('as', 4),\n",
       " ('science', 3),\n",
       " ('of', 3),\n",
       " ('in', 3),\n",
       " ('for', 3),\n",
       " ('graphic', 3),\n",
       " ('have', 3),\n",
       " ('student', 2),\n",
       " ('learning', 2),\n",
       " ('vision', 2),\n",
       " ('field', 2),\n",
       " ('designer', 2),\n",
       " ('my', 2),\n",
       " ('favorite', 2),\n",
       " ('also', 2),\n",
       " ('on', 2),\n",
       " ('video', 2)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## most common words top ten\n",
    "Top_ten = fdist.most_common(25)\n",
    "## total no of words according to combine frquency\n",
    "len(fdist)\n",
    "## total no of word token\n",
    "len(first_token)\n",
    "Top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_blank = blankline_tokenize(test_str)\n",
    "len(first_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', ','),\n",
       " (',', 'I'),\n",
       " ('I', 'am'),\n",
       " ('am', 'Sirmad'),\n",
       " ('Sirmad', 'Mahmood'),\n",
       " ('Mahmood', 'Hashmi'),\n",
       " ('Hashmi', '.'),\n",
       " ('.', 'I'),\n",
       " ('I', 'am'),\n",
       " ('am', 'an'),\n",
       " ('an', 'MSc'),\n",
       " ('MSc', 'Computer'),\n",
       " ('Computer', 'Science'),\n",
       " ('Science', 'student'),\n",
       " ('student', 'at'),\n",
       " ('at', 'the'),\n",
       " ('the', 'University'),\n",
       " ('University', 'of'),\n",
       " ('of', 'Debrecen'),\n",
       " ('Debrecen', ','),\n",
       " (',', 'Hungary'),\n",
       " ('Hungary', '.'),\n",
       " ('.', 'I'),\n",
       " ('I', 'am'),\n",
       " ('am', 'very'),\n",
       " ('very', 'much'),\n",
       " ('much', 'interested'),\n",
       " ('interested', 'in'),\n",
       " ('in', 'deep'),\n",
       " ('deep', 'learning'),\n",
       " ('learning', ','),\n",
       " (',', 'computer'),\n",
       " ('computer', 'vision'),\n",
       " ('vision', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'natural'),\n",
       " ('natural', 'language'),\n",
       " ('language', 'processing'),\n",
       " ('processing', '.'),\n",
       " ('.', 'I'),\n",
       " ('I', 'am'),\n",
       " ('am', 'looking'),\n",
       " ('looking', 'for'),\n",
       " ('for', 'a'),\n",
       " ('a', 'job'),\n",
       " ('job', 'as'),\n",
       " ('as', 'a'),\n",
       " ('a', 'data'),\n",
       " ('data', 'science'),\n",
       " ('science', 'engineer'),\n",
       " ('engineer', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'field'),\n",
       " ('field', 'of'),\n",
       " ('of', 'NLP'),\n",
       " ('NLP', 'or'),\n",
       " ('or', 'Computer'),\n",
       " ('Computer', 'Vision'),\n",
       " ('Vision', '.'),\n",
       " ('.', 'As'),\n",
       " ('As', 'a'),\n",
       " ('a', 'hobbyist'),\n",
       " ('hobbyist', ','),\n",
       " (',', 'I'),\n",
       " ('I', 'am'),\n",
       " ('am', 'a'),\n",
       " ('a', 'graphic'),\n",
       " ('graphic', 'designer'),\n",
       " ('designer', 'I'),\n",
       " ('I', 'sometimes'),\n",
       " ('sometimes', 'work'),\n",
       " ('work', 'as'),\n",
       " ('as', 'a'),\n",
       " ('a', 'freelance'),\n",
       " ('freelance', 'graphic'),\n",
       " ('graphic', 'designer'),\n",
       " ('designer', '.'),\n",
       " ('.', 'My'),\n",
       " ('My', 'favorite'),\n",
       " ('favorite', 'tool'),\n",
       " ('tool', 'for'),\n",
       " ('for', 'graphic'),\n",
       " ('graphic', 'design'),\n",
       " ('design', 'is'),\n",
       " ('is', 'Coreldraw'),\n",
       " ('Coreldraw', '.'),\n",
       " ('.', 'I'),\n",
       " ('I', 'have'),\n",
       " ('have', 'also'),\n",
       " ('also', 'worked'),\n",
       " ('worked', 'on'),\n",
       " ('on', 'several'),\n",
       " ('several', 'video'),\n",
       " ('video', 'projects'),\n",
       " ('projects', 'editing'),\n",
       " ('editing', 'projects'),\n",
       " ('projects', 'and'),\n",
       " ('and', '3d'),\n",
       " ('3d', 'animations'),\n",
       " ('animations', '.'),\n",
       " ('.', 'I'),\n",
       " ('I', 'have'),\n",
       " ('have', 'also'),\n",
       " ('also', 'built'),\n",
       " ('built', 'a'),\n",
       " ('a', 'video'),\n",
       " ('video', 'game'),\n",
       " ('game', 'for'),\n",
       " ('for', 'the'),\n",
       " ('the', 'Android'),\n",
       " ('Android', 'platform'),\n",
       " ('platform', 'using'),\n",
       " ('using', 'the'),\n",
       " ('the', 'unity3d'),\n",
       " ('unity3d', 'engine'),\n",
       " ('engine', '.'),\n",
       " ('.', 'As'),\n",
       " ('As', 'a'),\n",
       " ('a', 'computer'),\n",
       " ('computer', 'science'),\n",
       " ('science', 'student'),\n",
       " ('student', ','),\n",
       " (',', 'I'),\n",
       " ('I', 'have'),\n",
       " ('have', 'decent'),\n",
       " ('decent', 'knowledge'),\n",
       " ('knowledge', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'field'),\n",
       " ('field', 'of'),\n",
       " ('of', 'cybersecurity'),\n",
       " ('cybersecurity', 'and'),\n",
       " ('and', 'software'),\n",
       " ('software', 'development'),\n",
       " ('development', 'but'),\n",
       " ('but', 'now'),\n",
       " ('now', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'only'),\n",
       " ('only', 'working'),\n",
       " ('working', 'on'),\n",
       " ('on', 'machine'),\n",
       " ('machine', 'learning'),\n",
       " ('learning', 'concepts'),\n",
       " ('concepts', '.'),\n",
       " ('.', 'My'),\n",
       " ('My', 'favorite'),\n",
       " ('favorite', 'programming'),\n",
       " ('programming', 'languages'),\n",
       " ('languages', 'are'),\n",
       " ('are', 'Python'),\n",
       " ('Python', ','),\n",
       " (',', 'R'),\n",
       " ('R', ','),\n",
       " (',', 'C++'),\n",
       " ('C++', ','),\n",
       " (',', 'and'),\n",
       " ('and', ','),\n",
       " (',', 'Java'),\n",
       " ('Java', '.')]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bigram of my  words\n",
    "bigram_test = list(nltk.bigrams(first_token))\n",
    "bigram_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', ',', 'I'),\n",
       " (',', 'I', 'am'),\n",
       " ('I', 'am', 'Sirmad'),\n",
       " ('am', 'Sirmad', 'Mahmood'),\n",
       " ('Sirmad', 'Mahmood', 'Hashmi'),\n",
       " ('Mahmood', 'Hashmi', '.'),\n",
       " ('Hashmi', '.', 'I'),\n",
       " ('.', 'I', 'am'),\n",
       " ('I', 'am', 'an'),\n",
       " ('am', 'an', 'MSc'),\n",
       " ('an', 'MSc', 'Computer'),\n",
       " ('MSc', 'Computer', 'Science'),\n",
       " ('Computer', 'Science', 'student'),\n",
       " ('Science', 'student', 'at'),\n",
       " ('student', 'at', 'the'),\n",
       " ('at', 'the', 'University'),\n",
       " ('the', 'University', 'of'),\n",
       " ('University', 'of', 'Debrecen'),\n",
       " ('of', 'Debrecen', ','),\n",
       " ('Debrecen', ',', 'Hungary'),\n",
       " (',', 'Hungary', '.'),\n",
       " ('Hungary', '.', 'I'),\n",
       " ('.', 'I', 'am'),\n",
       " ('I', 'am', 'very'),\n",
       " ('am', 'very', 'much'),\n",
       " ('very', 'much', 'interested'),\n",
       " ('much', 'interested', 'in'),\n",
       " ('interested', 'in', 'deep'),\n",
       " ('in', 'deep', 'learning'),\n",
       " ('deep', 'learning', ','),\n",
       " ('learning', ',', 'computer'),\n",
       " (',', 'computer', 'vision'),\n",
       " ('computer', 'vision', ','),\n",
       " ('vision', ',', 'and'),\n",
       " (',', 'and', 'natural'),\n",
       " ('and', 'natural', 'language'),\n",
       " ('natural', 'language', 'processing'),\n",
       " ('language', 'processing', '.'),\n",
       " ('processing', '.', 'I'),\n",
       " ('.', 'I', 'am'),\n",
       " ('I', 'am', 'looking'),\n",
       " ('am', 'looking', 'for'),\n",
       " ('looking', 'for', 'a'),\n",
       " ('for', 'a', 'job'),\n",
       " ('a', 'job', 'as'),\n",
       " ('job', 'as', 'a'),\n",
       " ('as', 'a', 'data'),\n",
       " ('a', 'data', 'science'),\n",
       " ('data', 'science', 'engineer'),\n",
       " ('science', 'engineer', 'in'),\n",
       " ('engineer', 'in', 'the'),\n",
       " ('in', 'the', 'field'),\n",
       " ('the', 'field', 'of'),\n",
       " ('field', 'of', 'NLP'),\n",
       " ('of', 'NLP', 'or'),\n",
       " ('NLP', 'or', 'Computer'),\n",
       " ('or', 'Computer', 'Vision'),\n",
       " ('Computer', 'Vision', '.'),\n",
       " ('Vision', '.', 'As'),\n",
       " ('.', 'As', 'a'),\n",
       " ('As', 'a', 'hobbyist'),\n",
       " ('a', 'hobbyist', ','),\n",
       " ('hobbyist', ',', 'I'),\n",
       " (',', 'I', 'am'),\n",
       " ('I', 'am', 'a'),\n",
       " ('am', 'a', 'graphic'),\n",
       " ('a', 'graphic', 'designer'),\n",
       " ('graphic', 'designer', 'I'),\n",
       " ('designer', 'I', 'sometimes'),\n",
       " ('I', 'sometimes', 'work'),\n",
       " ('sometimes', 'work', 'as'),\n",
       " ('work', 'as', 'a'),\n",
       " ('as', 'a', 'freelance'),\n",
       " ('a', 'freelance', 'graphic'),\n",
       " ('freelance', 'graphic', 'designer'),\n",
       " ('graphic', 'designer', '.'),\n",
       " ('designer', '.', 'My'),\n",
       " ('.', 'My', 'favorite'),\n",
       " ('My', 'favorite', 'tool'),\n",
       " ('favorite', 'tool', 'for'),\n",
       " ('tool', 'for', 'graphic'),\n",
       " ('for', 'graphic', 'design'),\n",
       " ('graphic', 'design', 'is'),\n",
       " ('design', 'is', 'Coreldraw'),\n",
       " ('is', 'Coreldraw', '.'),\n",
       " ('Coreldraw', '.', 'I'),\n",
       " ('.', 'I', 'have'),\n",
       " ('I', 'have', 'also'),\n",
       " ('have', 'also', 'worked'),\n",
       " ('also', 'worked', 'on'),\n",
       " ('worked', 'on', 'several'),\n",
       " ('on', 'several', 'video'),\n",
       " ('several', 'video', 'projects'),\n",
       " ('video', 'projects', 'editing'),\n",
       " ('projects', 'editing', 'projects'),\n",
       " ('editing', 'projects', 'and'),\n",
       " ('projects', 'and', '3d'),\n",
       " ('and', '3d', 'animations'),\n",
       " ('3d', 'animations', '.'),\n",
       " ('animations', '.', 'I'),\n",
       " ('.', 'I', 'have'),\n",
       " ('I', 'have', 'also'),\n",
       " ('have', 'also', 'built'),\n",
       " ('also', 'built', 'a'),\n",
       " ('built', 'a', 'video'),\n",
       " ('a', 'video', 'game'),\n",
       " ('video', 'game', 'for'),\n",
       " ('game', 'for', 'the'),\n",
       " ('for', 'the', 'Android'),\n",
       " ('the', 'Android', 'platform'),\n",
       " ('Android', 'platform', 'using'),\n",
       " ('platform', 'using', 'the'),\n",
       " ('using', 'the', 'unity3d'),\n",
       " ('the', 'unity3d', 'engine'),\n",
       " ('unity3d', 'engine', '.'),\n",
       " ('engine', '.', 'As'),\n",
       " ('.', 'As', 'a'),\n",
       " ('As', 'a', 'computer'),\n",
       " ('a', 'computer', 'science'),\n",
       " ('computer', 'science', 'student'),\n",
       " ('science', 'student', ','),\n",
       " ('student', ',', 'I'),\n",
       " (',', 'I', 'have'),\n",
       " ('I', 'have', 'decent'),\n",
       " ('have', 'decent', 'knowledge'),\n",
       " ('decent', 'knowledge', 'in'),\n",
       " ('knowledge', 'in', 'the'),\n",
       " ('in', 'the', 'field'),\n",
       " ('the', 'field', 'of'),\n",
       " ('field', 'of', 'cybersecurity'),\n",
       " ('of', 'cybersecurity', 'and'),\n",
       " ('cybersecurity', 'and', 'software'),\n",
       " ('and', 'software', 'development'),\n",
       " ('software', 'development', 'but'),\n",
       " ('development', 'but', 'now'),\n",
       " ('but', 'now', 'i'),\n",
       " ('now', 'i', 'am'),\n",
       " ('i', 'am', 'only'),\n",
       " ('am', 'only', 'working'),\n",
       " ('only', 'working', 'on'),\n",
       " ('working', 'on', 'machine'),\n",
       " ('on', 'machine', 'learning'),\n",
       " ('machine', 'learning', 'concepts'),\n",
       " ('learning', 'concepts', '.'),\n",
       " ('concepts', '.', 'My'),\n",
       " ('.', 'My', 'favorite'),\n",
       " ('My', 'favorite', 'programming'),\n",
       " ('favorite', 'programming', 'languages'),\n",
       " ('programming', 'languages', 'are'),\n",
       " ('languages', 'are', 'Python'),\n",
       " ('are', 'Python', ','),\n",
       " ('Python', ',', 'R'),\n",
       " (',', 'R', ','),\n",
       " ('R', ',', 'C++'),\n",
       " (',', 'C++', ','),\n",
       " ('C++', ',', 'and'),\n",
       " (',', 'and', ','),\n",
       " ('and', ',', 'Java'),\n",
       " (',', 'Java', '.')]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## trigram of words\n",
    "trigram_test = list(nltk.trigrams(first_token))\n",
    "trigram_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', ',', 'I', 'am'),\n",
       " (',', 'I', 'am', 'Sirmad'),\n",
       " ('I', 'am', 'Sirmad', 'Mahmood'),\n",
       " ('am', 'Sirmad', 'Mahmood', 'Hashmi'),\n",
       " ('Sirmad', 'Mahmood', 'Hashmi', '.'),\n",
       " ('Mahmood', 'Hashmi', '.', 'I'),\n",
       " ('Hashmi', '.', 'I', 'am'),\n",
       " ('.', 'I', 'am', 'an'),\n",
       " ('I', 'am', 'an', 'MSc'),\n",
       " ('am', 'an', 'MSc', 'Computer'),\n",
       " ('an', 'MSc', 'Computer', 'Science'),\n",
       " ('MSc', 'Computer', 'Science', 'student'),\n",
       " ('Computer', 'Science', 'student', 'at'),\n",
       " ('Science', 'student', 'at', 'the'),\n",
       " ('student', 'at', 'the', 'University'),\n",
       " ('at', 'the', 'University', 'of'),\n",
       " ('the', 'University', 'of', 'Debrecen'),\n",
       " ('University', 'of', 'Debrecen', ','),\n",
       " ('of', 'Debrecen', ',', 'Hungary'),\n",
       " ('Debrecen', ',', 'Hungary', '.'),\n",
       " (',', 'Hungary', '.', 'I'),\n",
       " ('Hungary', '.', 'I', 'am'),\n",
       " ('.', 'I', 'am', 'very'),\n",
       " ('I', 'am', 'very', 'much'),\n",
       " ('am', 'very', 'much', 'interested'),\n",
       " ('very', 'much', 'interested', 'in'),\n",
       " ('much', 'interested', 'in', 'deep'),\n",
       " ('interested', 'in', 'deep', 'learning'),\n",
       " ('in', 'deep', 'learning', ','),\n",
       " ('deep', 'learning', ',', 'computer'),\n",
       " ('learning', ',', 'computer', 'vision'),\n",
       " (',', 'computer', 'vision', ','),\n",
       " ('computer', 'vision', ',', 'and'),\n",
       " ('vision', ',', 'and', 'natural'),\n",
       " (',', 'and', 'natural', 'language'),\n",
       " ('and', 'natural', 'language', 'processing'),\n",
       " ('natural', 'language', 'processing', '.'),\n",
       " ('language', 'processing', '.', 'I'),\n",
       " ('processing', '.', 'I', 'am'),\n",
       " ('.', 'I', 'am', 'looking'),\n",
       " ('I', 'am', 'looking', 'for'),\n",
       " ('am', 'looking', 'for', 'a'),\n",
       " ('looking', 'for', 'a', 'job'),\n",
       " ('for', 'a', 'job', 'as'),\n",
       " ('a', 'job', 'as', 'a'),\n",
       " ('job', 'as', 'a', 'data'),\n",
       " ('as', 'a', 'data', 'science'),\n",
       " ('a', 'data', 'science', 'engineer'),\n",
       " ('data', 'science', 'engineer', 'in'),\n",
       " ('science', 'engineer', 'in', 'the'),\n",
       " ('engineer', 'in', 'the', 'field'),\n",
       " ('in', 'the', 'field', 'of'),\n",
       " ('the', 'field', 'of', 'NLP'),\n",
       " ('field', 'of', 'NLP', 'or'),\n",
       " ('of', 'NLP', 'or', 'Computer'),\n",
       " ('NLP', 'or', 'Computer', 'Vision'),\n",
       " ('or', 'Computer', 'Vision', '.'),\n",
       " ('Computer', 'Vision', '.', 'As'),\n",
       " ('Vision', '.', 'As', 'a'),\n",
       " ('.', 'As', 'a', 'hobbyist'),\n",
       " ('As', 'a', 'hobbyist', ','),\n",
       " ('a', 'hobbyist', ',', 'I'),\n",
       " ('hobbyist', ',', 'I', 'am'),\n",
       " (',', 'I', 'am', 'a'),\n",
       " ('I', 'am', 'a', 'graphic'),\n",
       " ('am', 'a', 'graphic', 'designer'),\n",
       " ('a', 'graphic', 'designer', 'I'),\n",
       " ('graphic', 'designer', 'I', 'sometimes'),\n",
       " ('designer', 'I', 'sometimes', 'work'),\n",
       " ('I', 'sometimes', 'work', 'as'),\n",
       " ('sometimes', 'work', 'as', 'a'),\n",
       " ('work', 'as', 'a', 'freelance'),\n",
       " ('as', 'a', 'freelance', 'graphic'),\n",
       " ('a', 'freelance', 'graphic', 'designer'),\n",
       " ('freelance', 'graphic', 'designer', '.'),\n",
       " ('graphic', 'designer', '.', 'My'),\n",
       " ('designer', '.', 'My', 'favorite'),\n",
       " ('.', 'My', 'favorite', 'tool'),\n",
       " ('My', 'favorite', 'tool', 'for'),\n",
       " ('favorite', 'tool', 'for', 'graphic'),\n",
       " ('tool', 'for', 'graphic', 'design'),\n",
       " ('for', 'graphic', 'design', 'is'),\n",
       " ('graphic', 'design', 'is', 'Coreldraw'),\n",
       " ('design', 'is', 'Coreldraw', '.'),\n",
       " ('is', 'Coreldraw', '.', 'I'),\n",
       " ('Coreldraw', '.', 'I', 'have'),\n",
       " ('.', 'I', 'have', 'also'),\n",
       " ('I', 'have', 'also', 'worked'),\n",
       " ('have', 'also', 'worked', 'on'),\n",
       " ('also', 'worked', 'on', 'several'),\n",
       " ('worked', 'on', 'several', 'video'),\n",
       " ('on', 'several', 'video', 'projects'),\n",
       " ('several', 'video', 'projects', 'editing'),\n",
       " ('video', 'projects', 'editing', 'projects'),\n",
       " ('projects', 'editing', 'projects', 'and'),\n",
       " ('editing', 'projects', 'and', '3d'),\n",
       " ('projects', 'and', '3d', 'animations'),\n",
       " ('and', '3d', 'animations', '.'),\n",
       " ('3d', 'animations', '.', 'I'),\n",
       " ('animations', '.', 'I', 'have'),\n",
       " ('.', 'I', 'have', 'also'),\n",
       " ('I', 'have', 'also', 'built'),\n",
       " ('have', 'also', 'built', 'a'),\n",
       " ('also', 'built', 'a', 'video'),\n",
       " ('built', 'a', 'video', 'game'),\n",
       " ('a', 'video', 'game', 'for'),\n",
       " ('video', 'game', 'for', 'the'),\n",
       " ('game', 'for', 'the', 'Android'),\n",
       " ('for', 'the', 'Android', 'platform'),\n",
       " ('the', 'Android', 'platform', 'using'),\n",
       " ('Android', 'platform', 'using', 'the'),\n",
       " ('platform', 'using', 'the', 'unity3d'),\n",
       " ('using', 'the', 'unity3d', 'engine'),\n",
       " ('the', 'unity3d', 'engine', '.'),\n",
       " ('unity3d', 'engine', '.', 'As'),\n",
       " ('engine', '.', 'As', 'a'),\n",
       " ('.', 'As', 'a', 'computer'),\n",
       " ('As', 'a', 'computer', 'science'),\n",
       " ('a', 'computer', 'science', 'student'),\n",
       " ('computer', 'science', 'student', ','),\n",
       " ('science', 'student', ',', 'I'),\n",
       " ('student', ',', 'I', 'have'),\n",
       " (',', 'I', 'have', 'decent'),\n",
       " ('I', 'have', 'decent', 'knowledge'),\n",
       " ('have', 'decent', 'knowledge', 'in'),\n",
       " ('decent', 'knowledge', 'in', 'the'),\n",
       " ('knowledge', 'in', 'the', 'field'),\n",
       " ('in', 'the', 'field', 'of'),\n",
       " ('the', 'field', 'of', 'cybersecurity'),\n",
       " ('field', 'of', 'cybersecurity', 'and'),\n",
       " ('of', 'cybersecurity', 'and', 'software'),\n",
       " ('cybersecurity', 'and', 'software', 'development'),\n",
       " ('and', 'software', 'development', 'but'),\n",
       " ('software', 'development', 'but', 'now'),\n",
       " ('development', 'but', 'now', 'i'),\n",
       " ('but', 'now', 'i', 'am'),\n",
       " ('now', 'i', 'am', 'only'),\n",
       " ('i', 'am', 'only', 'working'),\n",
       " ('am', 'only', 'working', 'on'),\n",
       " ('only', 'working', 'on', 'machine'),\n",
       " ('working', 'on', 'machine', 'learning'),\n",
       " ('on', 'machine', 'learning', 'concepts'),\n",
       " ('machine', 'learning', 'concepts', '.'),\n",
       " ('learning', 'concepts', '.', 'My'),\n",
       " ('concepts', '.', 'My', 'favorite'),\n",
       " ('.', 'My', 'favorite', 'programming'),\n",
       " ('My', 'favorite', 'programming', 'languages'),\n",
       " ('favorite', 'programming', 'languages', 'are'),\n",
       " ('programming', 'languages', 'are', 'Python'),\n",
       " ('languages', 'are', 'Python', ','),\n",
       " ('are', 'Python', ',', 'R'),\n",
       " ('Python', ',', 'R', ','),\n",
       " (',', 'R', ',', 'C++'),\n",
       " ('R', ',', 'C++', ','),\n",
       " (',', 'C++', ',', 'and'),\n",
       " ('C++', ',', 'and', ','),\n",
       " (',', 'and', ',', 'Java'),\n",
       " ('and', ',', 'Java', '.')]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ngram_test = list(nltk.ngrams(first_token, 4))\n",
    "Ngram_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## performing stemming \n",
    "sec_test = 'my name is sirmad. i am having a tea. are you dancing ?. rumblining is bad.'\n",
    "pst = PorterStemmer()\n",
    "pst.stem('Having')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['having', 'eating ', 'doning', 'making']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have\n",
      "eating \n",
      "done\n",
      "make\n"
     ]
    }
   ],
   "source": [
    "sec_test1 = ['having' , 'eating ' , 'doning' , 'making']\n",
    "sec_test1\n",
    "for word in sec_test1:\n",
    "   print(pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hav\n",
      "eating \n",
      "don\n",
      "mak\n"
     ]
    }
   ],
   "source": [
    "sec_test1 = ['having' , 'eating ' , 'doning' , 'making']\n",
    "lst = LancasterStemmer()\n",
    "for word in sec_test1:\n",
    "   print(lst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem = WordNetLemmatizer()\n",
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "having\n",
      "eating \n",
      "doning\n",
      "making\n"
     ]
    }
   ],
   "source": [
    "for word in sec_test1:\n",
    "   print(word_lem.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slen = stopwords.words('english')\n",
    "len(slen)\n",
    "slen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = re.compile('[-.?!,:;()|0-9]')\n",
    "post_pun_word = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Sirmad',\n",
       " 'Mahmood',\n",
       " 'Hashmi',\n",
       " 'I',\n",
       " 'am',\n",
       " 'an',\n",
       " 'MSc',\n",
       " 'Computer',\n",
       " 'Science',\n",
       " 'student',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Debrecen',\n",
       " 'Hungary',\n",
       " 'I',\n",
       " 'am',\n",
       " 'very',\n",
       " 'much',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'and',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'I',\n",
       " 'am',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'a',\n",
       " 'job',\n",
       " 'as',\n",
       " 'a',\n",
       " 'data',\n",
       " 'science',\n",
       " 'engineer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'or',\n",
       " 'Computer',\n",
       " 'Vision',\n",
       " 'As',\n",
       " 'a',\n",
       " 'hobbyist',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'graphic',\n",
       " 'designer',\n",
       " 'I',\n",
       " 'sometimes',\n",
       " 'work',\n",
       " 'as',\n",
       " 'a',\n",
       " 'freelance',\n",
       " 'graphic',\n",
       " 'designer',\n",
       " 'My',\n",
       " 'favorite',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'graphic',\n",
       " 'design',\n",
       " 'is',\n",
       " 'Coreldraw',\n",
       " 'I',\n",
       " 'have',\n",
       " 'also',\n",
       " 'worked',\n",
       " 'on',\n",
       " 'several',\n",
       " 'video',\n",
       " 'projects',\n",
       " 'editing',\n",
       " 'projects',\n",
       " 'and',\n",
       " 'd',\n",
       " 'animations',\n",
       " 'I',\n",
       " 'have',\n",
       " 'also',\n",
       " 'built',\n",
       " 'a',\n",
       " 'video',\n",
       " 'game',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Android',\n",
       " 'platform',\n",
       " 'using',\n",
       " 'the',\n",
       " 'unityd',\n",
       " 'engine',\n",
       " 'As',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'student',\n",
       " 'I',\n",
       " 'have',\n",
       " 'decent',\n",
       " 'knowledge',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'cybersecurity',\n",
       " 'and',\n",
       " 'software',\n",
       " 'development',\n",
       " 'but',\n",
       " 'now',\n",
       " 'i',\n",
       " 'am',\n",
       " 'only',\n",
       " 'working',\n",
       " 'on',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'concepts',\n",
       " 'My',\n",
       " 'favorite',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'are',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'C++',\n",
       " 'and',\n",
       " 'Java']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for words in first_token:\n",
    "    word = punctuation.sub(\"\", words)\n",
    "    if len(word)> 0:\n",
    "        post_pun_word.append(word)\n",
    "\n",
    "post_pun_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 10),\n",
       " ('i', 10),\n",
       " ('.', 10),\n",
       " ('a', 7),\n",
       " ('am', 6),\n",
       " ('the', 5),\n",
       " ('computer', 4),\n",
       " ('and', 4),\n",
       " ('as', 4),\n",
       " ('science', 3),\n",
       " ('of', 3),\n",
       " ('in', 3),\n",
       " ('for', 3),\n",
       " ('graphic', 3),\n",
       " ('have', 3),\n",
       " ('student', 2),\n",
       " ('learning', 2),\n",
       " ('vision', 2),\n",
       " ('field', 2),\n",
       " ('designer', 2),\n",
       " ('my', 2),\n",
       " ('favorite', 2),\n",
       " ('also', 2),\n",
       " ('on', 2),\n",
       " ('video', 2)]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_pun_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'a', 'king', 'of', 'the', 'variables']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tok1 = \"i am a king of the variables\"\n",
    "sent_tok = word_tokenize(sent_tok1)\n",
    "sent_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello', 'NNP'), (',', ','), ('I', 'PRP'), ('am', 'VBP'), ('Sirmad', 'JJ'), ('Mahmood', 'NNP'), ('Hashmi', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('an', 'DT'), ('MSc', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('student', 'NN'), ('at', 'IN'), ('the', 'DT'), ('University', 'NNP'), ('of', 'IN'), ('Debrecen', 'NNP'), (',', ','), ('Hungary', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('very', 'RB'), ('much', 'RB'), ('interested', 'JJ'), ('in', 'IN'), ('deep', 'JJ'), ('learning', 'NN'), (',', ','), ('computer', 'NN'), ('vision', 'NN'), (',', ','), ('and', 'CC'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('looking', 'VBG'), ('for', 'IN'), ('a', 'DT'), ('job', 'NN'), ('as', 'IN'), ('a', 'DT'), ('data', 'NN'), ('science', 'NN'), ('engineer', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('NLP', 'NNP'), ('or', 'CC'), ('Computer', 'NNP'), ('Vision', 'NNP'), ('.', '.'), ('As', 'IN'), ('a', 'DT'), ('hobbyist', 'NN'), (',', ','), ('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('graphic', 'JJ'), ('designer', 'NN'), ('I', 'PRP'), ('sometimes', 'RB'), ('work', 'VBP'), ('as', 'IN'), ('a', 'DT'), ('freelance', 'NN'), ('graphic', 'JJ'), ('designer', 'NN'), ('.', '.'), ('My', 'PRP$'), ('favorite', 'JJ'), ('tool', 'NN'), ('for', 'IN'), ('graphic', 'JJ'), ('design', 'NN'), ('is', 'VBZ'), ('Coreldraw', 'NNP'), ('.', '.'), ('I', 'PRP'), ('have', 'VBP'), ('also', 'RB'), ('worked', 'VBN'), ('on', 'IN'), ('several', 'JJ'), ('video', 'JJ'), ('projects', 'NNS'), ('editing', 'VBG'), ('projects', 'NNS'), ('and', 'CC'), ('3d', 'CD'), ('animations', 'NNS'), ('.', '.'), ('I', 'PRP'), ('have', 'VBP'), ('also', 'RB'), ('built', 'VBN'), ('a', 'DT'), ('video', 'NN'), ('game', 'NN'), ('for', 'IN'), ('the', 'DT'), ('Android', 'NNP'), ('platform', 'NN'), ('using', 'VBG'), ('the', 'DT'), ('unity3d', 'JJ'), ('engine', 'NN'), ('.', '.'), ('As', 'IN'), ('a', 'DT'), ('computer', 'NN'), ('science', 'NN'), ('student', 'NN'), (',', ','), ('I', 'PRP'), ('have', 'VBP'), ('decent', 'JJ'), ('knowledge', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('cybersecurity', 'NN'), ('and', 'CC'), ('software', 'NN'), ('development', 'NN'), ('but', 'CC'), ('now', 'RB'), ('i', 'VBZ'), ('am', 'VBP'), ('only', 'RB'), ('working', 'VBG'), ('on', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('concepts', 'NNS'), ('.', '.'), ('My', 'PRP$'), ('favorite', 'JJ'), ('programming', 'NN'), ('languages', 'NNS'), ('are', 'VBP'), ('Python', 'NNP'), (',', ','), ('R', 'NNP'), (',', ','), ('C++', 'NNP'), (',', ','), ('and', 'CC'), (',', ','), ('Java', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## recoginize POS\n",
    "for word in first_token:\n",
    "    showtok = nltk.pos_tag(first_token)\n",
    "\n",
    "print(showtok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Hello/NNP)\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  (PERSON Sirmad/JJ Mahmood/NNP Hashmi/NNP)\n",
      "  ./.\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  an/DT\n",
      "  (ORGANIZATION MSc/NNP Computer/NNP Science/NNP)\n",
      "  student/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION University/NNP)\n",
      "  of/IN\n",
      "  (GPE Debrecen/NNP)\n",
      "  ,/,\n",
      "  (GPE Hungary/NNP)\n",
      "  ./.\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  very/RB\n",
      "  much/RB\n",
      "  interested/JJ\n",
      "  in/IN\n",
      "  deep/JJ\n",
      "  learning/NN\n",
      "  ,/,\n",
      "  computer/NN\n",
      "  vision/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  natural/JJ\n",
      "  language/NN\n",
      "  processing/NN\n",
      "  ./.\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  looking/VBG\n",
      "  for/IN\n",
      "  a/DT\n",
      "  job/NN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  data/NN\n",
      "  science/NN\n",
      "  engineer/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  field/NN\n",
      "  of/IN\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  or/CC\n",
      "  (ORGANIZATION Computer/NNP Vision/NNP)\n",
      "  ./.\n",
      "  As/IN\n",
      "  a/DT\n",
      "  hobbyist/NN\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  a/DT\n",
      "  graphic/JJ\n",
      "  designer/NN\n",
      "  I/PRP\n",
      "  sometimes/RB\n",
      "  work/VBP\n",
      "  as/IN\n",
      "  a/DT\n",
      "  freelance/NN\n",
      "  graphic/JJ\n",
      "  designer/NN\n",
      "  ./.\n",
      "  My/PRP$\n",
      "  favorite/JJ\n",
      "  tool/NN\n",
      "  for/IN\n",
      "  graphic/JJ\n",
      "  design/NN\n",
      "  is/VBZ\n",
      "  (PERSON Coreldraw/NNP)\n",
      "  ./.\n",
      "  I/PRP\n",
      "  have/VBP\n",
      "  also/RB\n",
      "  worked/VBN\n",
      "  on/IN\n",
      "  several/JJ\n",
      "  video/JJ\n",
      "  projects/NNS\n",
      "  editing/VBG\n",
      "  projects/NNS\n",
      "  and/CC\n",
      "  3d/CD\n",
      "  animations/NNS\n",
      "  ./.\n",
      "  I/PRP\n",
      "  have/VBP\n",
      "  also/RB\n",
      "  built/VBN\n",
      "  a/DT\n",
      "  video/NN\n",
      "  game/NN\n",
      "  for/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Android/NNP)\n",
      "  platform/NN\n",
      "  using/VBG\n",
      "  the/DT\n",
      "  unity3d/JJ\n",
      "  engine/NN\n",
      "  ./.\n",
      "  As/IN\n",
      "  a/DT\n",
      "  computer/NN\n",
      "  science/NN\n",
      "  student/NN\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  have/VBP\n",
      "  decent/JJ\n",
      "  knowledge/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  field/NN\n",
      "  of/IN\n",
      "  cybersecurity/NN\n",
      "  and/CC\n",
      "  software/NN\n",
      "  development/NN\n",
      "  but/CC\n",
      "  now/RB\n",
      "  i/VBZ\n",
      "  am/VBP\n",
      "  only/RB\n",
      "  working/VBG\n",
      "  on/IN\n",
      "  machine/NN\n",
      "  learning/NN\n",
      "  concepts/NNS\n",
      "  ./.\n",
      "  My/PRP$\n",
      "  favorite/JJ\n",
      "  programming/NN\n",
      "  languages/NNS\n",
      "  are/VBP\n",
      "  (PERSON Python/NNP)\n",
      "  ,/,\n",
      "  (GPE R/NNP)\n",
      "  ,/,\n",
      "  C++/NNP\n",
      "  ,/,\n",
      "  and/CC\n",
      "  ,/,\n",
      "  (PERSON Java/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "## name entity recogination\n",
    "NeR_test = ne_chunk(showtok)\n",
    "print(NeR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chunking \n",
    "grammar = r\"NP:{<DT>?<JJ>*<NN>}\" \n",
    "chunk_parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_widget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             subprocess.call([find_binary('gs', binary_names=['gswin32c.exe', 'gswin64c.exe'], env_vars=['PATH'], verbose=False)] +\n\u001b[0m\u001b[0;32m    731\u001b[0m                             \u001b[1;34m'-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile={0:} {1:}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                             .format(out_path, in_path).split())\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    602\u001b[0m                 binary_names=None, url=None, verbose=False):\n\u001b[0;32m    603\u001b[0m     return next(find_binary_iter(name, path_to_bin, env_vars, searchpath,\n\u001b[1;32m--> 604\u001b[1;33m                                  binary_names, url, verbose))\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m def find_jar_iter(name_pattern, path_to_jar=None, env_vars=(),\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \"\"\"\n\u001b[0;32m    597\u001b[0m     for file in  find_file_iter(path_to_bin or name, env_vars, searchpath, binary_names,\n\u001b[1;32m--> 598\u001b[1;33m                      url, verbose):\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    567\u001b[0m                         (filename, url))\n\u001b[0;32m    568\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n==========================================================================="
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('Hello', 'NNP'), (',', ','), ('I', 'PRP'), ('am', 'VBP'), ('Sirmad', 'JJ'), ('Mahmood', 'NNP'), ('Hashmi', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('an', 'DT'), ('MSc', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), Tree('NP', [('student', 'NN')]), ('at', 'IN'), ('the', 'DT'), ('University', 'NNP'), ('of', 'IN'), ('Debrecen', 'NNP'), (',', ','), ('Hungary', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('very', 'RB'), ('much', 'RB'), ('interested', 'JJ'), ('in', 'IN'), Tree('NP', [('deep', 'JJ'), ('learning', 'NN')]), (',', ','), Tree('NP', [('computer', 'NN')]), Tree('NP', [('vision', 'NN')]), (',', ','), ('and', 'CC'), Tree('NP', [('natural', 'JJ'), ('language', 'NN')]), Tree('NP', [('processing', 'NN')]), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('looking', 'VBG'), ('for', 'IN'), Tree('NP', [('a', 'DT'), ('job', 'NN')]), ('as', 'IN'), Tree('NP', [('a', 'DT'), ('data', 'NN')]), Tree('NP', [('science', 'NN')]), Tree('NP', [('engineer', 'NN')]), ('in', 'IN'), Tree('NP', [('the', 'DT'), ('field', 'NN')]), ('of', 'IN'), ('NLP', 'NNP'), ('or', 'CC'), ('Computer', 'NNP'), ('Vision', 'NNP'), ('.', '.'), ('As', 'IN'), Tree('NP', [('a', 'DT'), ('hobbyist', 'NN')]), (',', ','), ('I', 'PRP'), ('am', 'VBP'), Tree('NP', [('a', 'DT'), ('graphic', 'JJ'), ('designer', 'NN')]), ('I', 'PRP'), ('sometimes', 'RB'), ('work', 'VBP'), ('as', 'IN'), Tree('NP', [('a', 'DT'), ('freelance', 'NN')]), Tree('NP', [('graphic', 'JJ'), ('designer', 'NN')]), ('.', '.'), ('My', 'PRP$'), Tree('NP', [('favorite', 'JJ'), ('tool', 'NN')]), ('for', 'IN'), Tree('NP', [('graphic', 'JJ'), ('design', 'NN')]), ('is', 'VBZ'), ('Coreldraw', 'NNP'), ('.', '.'), ('I', 'PRP'), ('have', 'VBP'), ('also', 'RB'), ('worked', 'VBN'), ('on', 'IN'), ('several', 'JJ'), ('video', 'JJ'), ('projects', 'NNS'), ('editing', 'VBG'), ('projects', 'NNS'), ('and', 'CC'), ('3d', 'CD'), ('animations', 'NNS'), ('.', '.'), ('I', 'PRP'), ('have', 'VBP'), ('also', 'RB'), ('built', 'VBN'), Tree('NP', [('a', 'DT'), ('video', 'NN')]), Tree('NP', [('game', 'NN')]), ('for', 'IN'), ('the', 'DT'), ('Android', 'NNP'), Tree('NP', [('platform', 'NN')]), ('using', 'VBG'), Tree('NP', [('the', 'DT'), ('unity3d', 'JJ'), ('engine', 'NN')]), ('.', '.'), ('As', 'IN'), Tree('NP', [('a', 'DT'), ('computer', 'NN')]), Tree('NP', [('science', 'NN')]), Tree('NP', [('student', 'NN')]), (',', ','), ('I', 'PRP'), ('have', 'VBP'), Tree('NP', [('decent', 'JJ'), ('knowledge', 'NN')]), ('in', 'IN'), Tree('NP', [('the', 'DT'), ('field', 'NN')]), ('of', 'IN'), Tree('NP', [('cybersecurity', 'NN')]), ('and', 'CC'), Tree('NP', [('software', 'NN')]), Tree('NP', [('development', 'NN')]), ('but', 'CC'), ('now', 'RB'), ('i', 'VBZ'), ('am', 'VBP'), ('only', 'RB'), ('working', 'VBG'), ('on', 'IN'), Tree('NP', [('machine', 'NN')]), Tree('NP', [('learning', 'NN')]), ('concepts', 'NNS'), ('.', '.'), ('My', 'PRP$'), Tree('NP', [('favorite', 'JJ'), ('programming', 'NN')]), ('languages', 'NNS'), ('are', 'VBP'), ('Python', 'NNP'), (',', ','), ('R', 'NNP'), (',', ','), ('C++', 'NNP'), (',', ','), ('and', 'CC'), (',', ','), ('Java', 'NNP'), ('.', '.')])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_result = chunk_parser.parse(showtok)\n",
    "chunk_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
